{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac340d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n",
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "#### boiler plate code\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])\n",
    "\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n",
    "\n",
    "\n",
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e86b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ee3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) # 30,64\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1 # 27 x 64\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e47e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4791853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f96ab815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar  torch.Size([1, 64])\n",
      "probs torch.Size([32, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3252, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation 32 examples x 64 output neurons(32 egs x 30 emb   x   30 x 64 = 32 egs x 64)\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True) # 1 x 164\n",
    "\n",
    "bndiff = hprebn - bnmeani # 32 x 64 - 1 x 64 (broadcast 64 times) = 32 x 64\n",
    "bndiff2 = bndiff**2 # squaring each term - 32 x 64\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) # 1 x 64\n",
    "\n",
    "print('bnvar ',bnvar.shape) \n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "print('probs', logprobs.shape)\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00442c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dlogprobs | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss/dprobs    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dcounts_sum_inv | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dcounts_sum | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dcounts | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dnorm_logits | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dlogit_maxes | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dlogits | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dh     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dW2    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_db2    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dloss_by_dhpreact | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dloss_by_dbngain | exact: False | approximate: True  | maxdiff: 2.0954757928848267e-09\n",
      "dloss_by_dbnraw | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
      "dloss_by_dbnbias | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "dloss_by_dbnvar_inv | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "dloss_by_dbnvar | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "dloss_by_dbndiff2 | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
      "dloss_by_dbndiff | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dloss_by_dbnmeani | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "dloss_by_dhprebn | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dloss_by_dembcat | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "dloss_by_dW1    | exact: False | approximate: True  | maxdiff: 4.423782229423523e-09\n",
      "dloss_by_db1    | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-09\n",
      "dloss_by_demb   | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "dloss_by_dC     | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "### back prop step by step\n",
    "# loss = 1/32(-loss1 + -loss2 + -loss3 ... -loss32)\n",
    "# dloss/logprobs = -1/32 the ones that are participating, Yb column ones\n",
    "# dloss/logprobs = 0, the rest of the columns\n",
    "dloss_by_dlogprobs = torch.zeros(32,27)\n",
    "dloss_by_dlogprobs[range(n), Yb] = -1/32\n",
    "\n",
    "cmp('dloss/dlogprobs', dloss_by_dlogprobs, logprobs)\n",
    "\n",
    "dlogprobs_by_dprobs = 1/probs\n",
    "dloss_by_dprobs = dloss_by_dlogprobs * dlogprobs_by_dprobs\n",
    "\n",
    "cmp('dloss/dprobs ', dloss_by_dprobs, probs)\n",
    "\n",
    "dprobs_by_dcounts_sum_inv = counts\n",
    "dloss_by_dcounts_sum_inv = (dprobs_by_dcounts_sum_inv * dloss_by_dprobs).sum(1, keepdim=True)\n",
    "\n",
    "# 32 x 27\n",
    "# 2 example, 2 x 27\n",
    "# probs = counts=2 x 27  * counts_sum_inv=2 x 1(2 x 27)\n",
    "# c1*a c2*a ,,,c27*a\n",
    "# d1*b d2*b ,,,d27*b\n",
    "# loss due to a will be additive!\n",
    "# c1 + c2 + c3..\n",
    "# d1 + d2 + d3..\n",
    "cmp('dloss_by_dcounts_sum_inv', dloss_by_dcounts_sum_inv, counts_sum_inv)\n",
    "# print(dloss_by_dcounts_sum_inv.shape)\n",
    "\n",
    "# print(counts.shape) # 32 x 27\n",
    "dprobs_by_dcounts = counts_sum_inv\n",
    "# print(dprobs_by_dcounts.shape) # 32 x 1\n",
    "# print(dloss_by_dprobs.shape) # 32 x 27\n",
    "dloss_by_dcounts = dprobs_by_dcounts * dloss_by_dprobs # 32 x 27\n",
    "# print(dloss_by_dcounts.shape)\n",
    "# cmp('dloss_by_dcounts', dloss_by_dcounts, counts)\n",
    "# THIS IS FALSE BECAUSE counts is used at 2 places, other contri is not counted\n",
    "\n",
    "# print(counts_sum_inv.shape) # 32 x 1\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# print(counts_sum.shape) # 32 x 1\n",
    "dcounts_sum_inv_by_dcounts_sum = -(counts_sum**-2)\n",
    "dloss_by_dcounts_sum = dloss_by_dcounts_sum_inv * dcounts_sum_inv_by_dcounts_sum\n",
    "cmp('dloss_by_dcounts_sum',dloss_by_dcounts_sum, counts_sum)\n",
    "\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# print(counts_sum.shape) # 32 x 1\n",
    "# print(counts.shape) # 32 x 27\n",
    "# 32 x 27 -> 32 x 1 \n",
    "# a1 a2 a27\n",
    "# b1 b2 b27\n",
    "\n",
    "dcounts_sum_by_dcounts = torch.ones(32,27)\n",
    "dloss_by_dcounts += dloss_by_dcounts_sum * dcounts_sum_by_dcounts\n",
    "cmp('dloss_by_dcounts',dloss_by_dcounts,counts)\n",
    "\n",
    "# counts = norm_logits.exp()\n",
    "dcounts_by_dnorm_logits = norm_logits.exp()\n",
    "dloss_by_dnorm_logits = dloss_by_dcounts * dcounts_by_dnorm_logits\n",
    "cmp('dloss_by_dnorm_logits', dloss_by_dnorm_logits, norm_logits)\n",
    "\n",
    "\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# print(logits.shape) # 32 x 27\n",
    "# print(logit_maxes.shape) # 32 x 1\n",
    "dnorm_logits_by_dlogits = torch.ones_like(logits)\n",
    "dloss_by_dlogits = dloss_by_dnorm_logits * dnorm_logits_by_dlogits\n",
    "# cmp('dloss_by_dlogits',dloss_by_dlogits,logits)\n",
    "# This will be false because logits has one more branch\n",
    "\n",
    "# print(logit_maxes.shape) # 32 x 1\n",
    "dnorm_logits_by_dlogit_maxes = -1.0 * torch.ones(32,1)\n",
    "dloss_by_dlogit_maxes = dloss_by_dnorm_logits.sum(1, keepdim=True) * dnorm_logits_by_dlogit_maxes\n",
    "# print(dnorm_logits_by_dlogit_maxes.shape) # 32 x 1\n",
    "# print(dloss_by_dnorm_logits.shape) # 32 x 27\n",
    "cmp('dloss_by_dlogit_maxes', dloss_by_dlogit_maxes, logit_maxes)\n",
    "\n",
    "\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# print(logits.shape) # 32 x 27\n",
    "dlogit_maxes_by_dlogits = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1])\n",
    "dloss_by_dlogits += dloss_by_dlogit_maxes * dlogit_maxes_by_dlogits\n",
    "# print(dloss_by_dlogits.shape) # 32 x 27\n",
    "cmp('dloss_by_dlogits',dloss_by_dlogits,logits)\n",
    "\n",
    "# print(dloss_by_dlogits.shape) # 32 x 27\n",
    "# logits = h @ W2 + b2 # output layer\n",
    "# print(logits.shape, h.shape, W2.shape, b2.shape)\n",
    "# torch.Size([32, 27]) torch.Size([32, 64]) torch.Size([64, 27]) torch.Size([27])\n",
    "dlogits_by_dh = W2 # 64 x 27\n",
    "dloss_by_dh = dloss_by_dlogits @ torch.transpose(dlogits_by_dh,0,1)\n",
    "# print(dloss_by_dh.shape) # 32 x 64\n",
    "# torch.Size([32, 64]) =  ,32 x 27 @ 64 x 27'\n",
    "cmp('dloss_by_dh', dloss_by_dh, h)\n",
    "\n",
    "# W2.shape = 64 x 27, we want\n",
    "# loss/logits = 32 x 27\n",
    "# logits/W2 = 32 x 64\n",
    "\n",
    "# 32 x 64 ' @ 32 x 27 = 64 x 27\n",
    "dlogits_by_dW2 = h # 32 x 64\n",
    "dloss_by_dW2 = torch.transpose(dlogits_by_dW2,0,1) @ dloss_by_dlogits\n",
    "# print(dloss_by_dW2.shape) # 64 x 27\n",
    "cmp('dloss_by_dW2', dloss_by_dW2, W2)\n",
    "\n",
    "# b2.shape = 27\n",
    "dlogits_by_db2 = torch.ones_like(b2)\n",
    "dloss_by_db2 = dloss_by_dlogits.sum(0,keepdim=True) * dlogits_by_db2\n",
    "# print(dloss_by_db2.shape) # 1 x 27\n",
    "cmp('dloss_by_db2', dloss_by_db2, b2)\n",
    "\n",
    "# h = torch.tanh(hpreact) # hidden layer\n",
    "# print(hpreact.shape) # 32 x 64\n",
    "#  print(dloss_by_dh.shape) # 32 x 64\n",
    "dh_by_dhpreact = 1.0 - h**2\n",
    "# print(dh_by_dhpreact.shape)\n",
    "dloss_by_dhpreact = dh_by_dhpreact * dloss_by_dh\n",
    "# print(dloss_by_dhpreact.shape) # 32 x 64\n",
    "cmp('dloss_by_dhpreact', dloss_by_dhpreact, hpreact)\n",
    "\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "# print(bngain.shape) # 1 x 64\n",
    "# print(bnraw.shape) # 32 x 64\n",
    "# print(dloss_by_dhpreact.shape) # 32 x 64\n",
    "\n",
    "dhpreact_by_dbngain = bnraw\n",
    "# print(dhpreact_by_dbngain.shape) # 32 x 64\n",
    "dloss_by_dbngain = (dloss_by_dhpreact * dhpreact_by_dbngain).sum(0, keepdim=True)\n",
    "# print(dloss_by_dbngain.shape) # 1 x 64\n",
    "cmp('dloss_by_dbngain', dloss_by_dbngain, bngain)\n",
    "\n",
    "\n",
    "# print(bnraw.shape) # 32 x 64\n",
    "dhpreact_by_dbnraw = bngain\n",
    "# print(dhpreact_by_dbnraw.shape) # 1 x 64\n",
    "# print(dloss_by_dhpreact.shape) # 32 x 64\n",
    "dloss_by_dbnraw = (dloss_by_dhpreact * dhpreact_by_dbnraw)\n",
    "# print(dloss_by_dbnraw.shape) # 32 x 64\n",
    "cmp('dloss_by_dbnraw', dloss_by_dbnraw, bnraw)\n",
    "\n",
    "# print(bnbias.shape) # 1 x 64\n",
    "dhpreact_by_dbnbias = torch.ones_like(bnbias)\n",
    "dloss_by_dbnbias = (dloss_by_dhpreact * dhpreact_by_dbnbias).sum(0, keepdim=True)\n",
    "# print(dloss_by_dbnbias.shape)\n",
    "cmp('dloss_by_dbnbias', dloss_by_dbnbias, bnbias)\n",
    "\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# print(bndiff.shape) # 32 x 64\n",
    "# print(bnvar_inv.shape) # 1 x 64\n",
    "dbnraw_by_dbndiff = bnvar_inv\n",
    "# print(dloss_by_dbnraw.shape) # 32 x 64\n",
    "dloss_by_dbndiff = dloss_by_dbnraw * dbnraw_by_dbndiff\n",
    "# dloss_by_dbndiff = bnvar_inv* (bngain*(1.0-h**2)*(dloss_by_dlogits @ W2.T))\n",
    "# print(dloss_by_dbndiff.shape) # 32 x 64\n",
    "# cmp('dloss_by_dbndiff',dloss_by_dbndiff, bndiff)\n",
    "# THIS IS FALSE BECAUSE ITS NOT YET DONE\n",
    "\n",
    "dbnraw_by_dbnvar_inv = bndiff\n",
    "# print(dbnraw_by_dbnvar_inv.shape) # 32 x 64\n",
    "dloss_by_dbnvar_inv = (dloss_by_dbnraw * dbnraw_by_dbnvar_inv).sum(0, keepdim=True)\n",
    "cmp('dloss_by_dbnvar_inv', dloss_by_dbnvar_inv, bnvar_inv)\n",
    "\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# print(bnvar.shape)  1 x 64\n",
    "dbnvar_inv_by_dbnvar = -0.5*(bnvar +  1e-5)**-1.5\n",
    "# print(dbnvar_inv_by_dbnvar.shape) # 1 x 64\n",
    "# print(dloss_by_dbnvar_inv.shape)# 1 x 64\n",
    "dloss_by_dbnvar = dloss_by_dbnvar_inv * dbnvar_inv_by_dbnvar\n",
    "# print(dloss_by_dbnvar.shape) # 1 x 64\n",
    "cmp('dloss_by_dbnvar',dloss_by_dbnvar, bnvar)\n",
    "\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) # 1 x 64\n",
    "# print(bnvar.shape) # 1 x 64\n",
    "# print(bndiff2.shape) # 32 x 64\n",
    "dbnvar_by_dbndiff2 = 1/(n-1)*torch.ones(32,64)\n",
    "dloss_by_dbndiff2 = dloss_by_dbnvar * dbnvar_by_dbndiff2\n",
    "cmp('dloss_by_dbndiff2',dloss_by_dbndiff2, bndiff2) \n",
    "\n",
    "\n",
    "# bndiff2 = bndiff**2 # squaring each term - 32 x 64\n",
    "dbndiff2_by_dbndiff = 2*bndiff\n",
    "dloss_by_dbndiff += dloss_by_dbndiff2 * dbndiff2_by_dbndiff\n",
    "cmp('dloss_by_dbndiff',dloss_by_dbndiff,bndiff)\n",
    "\n",
    "# bndiff = hprebn - bnmeani # 32 x 64 - 32 x 1 (broadcast 64 times) = 32 x 64\n",
    "# print(bndiff.shape) # 32 x 64\n",
    "# print(hprebn.shape) # 32 x 64\n",
    "# print(bnmeani.shape) # 1 x 64\n",
    "dbndiff_by_dhprebn = torch.ones(32,64)\n",
    "dloss_by_dhprebn = dloss_by_dbndiff * dbndiff_by_dhprebn\n",
    "# print(dloss_by_dhprebn.shape) # 32 x 64\n",
    "# cmp('dloss_by_dhprebn',dloss_by_dhprebn, hprebn)\n",
    "# THIS IS FALSE, BECAUSE THERE IS ANOTHER BRANCH of hprebn\n",
    "\n",
    "dbndiff_by_dbnmeani = -1.0*torch.ones(1,64)\n",
    "dloss_by_dbnmeani = (dloss_by_dbndiff * dbndiff_by_dbnmeani).sum(0, keepdim=True)\n",
    "# print(dloss_by_dbmeani.shape)\n",
    "cmp('dloss_by_dbnmeani',dloss_by_dbnmeani, bnmeani)\n",
    "# print(dloss_by_dbndiff.shape) # 32 x 64\n",
    "\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True) # 32 x 1\n",
    "dbnmeani_by_dhprebn = 1/n * torch.ones(32,64)\n",
    "dloss_by_dhprebn += dloss_by_dbnmeani * dbnmeani_by_dhprebn\n",
    "cmp('dloss_by_dhprebn',dloss_by_dhprebn, hprebn)\n",
    "\n",
    "# hprebn = embcat @ W1 + b1 # hidden layer pre-activation 32 examples x 64 output neurons(32 egs x 30 emb   x   30 x 64 = 32 egs x 64)\n",
    "# print(hprebn.shape)  # 32 x 64\n",
    "# print(embcat.shape) # 32 x 30\n",
    "# print(W1.shape) # 30 x 64\n",
    "# print(b1.shape) # 64\n",
    "dhprebn_by_dembcat = W1 # 30 x 64\n",
    "# 32 x 30 = 64 x 32. T @ 30 x 64. T  \n",
    "# print(dloss_by_dhprebn.shape)# 32 x 64\n",
    "dloss_by_dembcat = dloss_by_dhprebn @ dhprebn_by_dembcat.T\n",
    "# print(dloss_by_dembcat.shape)\n",
    "cmp('dloss_by_dembcat', dloss_by_dembcat, embcat)\n",
    "\n",
    "dhprebn_by_dW1 = embcat # 32 x 30\n",
    "# 30 x 64 = 32 x 30.T  @ 32 x 64  \n",
    "dloss_by_dW1 = dhprebn_by_dW1.T @ dloss_by_dhprebn\n",
    "# print(dloss_by_dW1.shape)\n",
    "cmp('dloss_by_dW1',dloss_by_dW1, W1)\n",
    "\n",
    "dhprebn_by_db1 = torch.ones_like(b1)\n",
    "dloss_by_db1 = (dloss_by_dhprebn * dhprebn_by_db1).sum(0,keepdim=True)\n",
    "# print(dloss_by_db1.shape)\n",
    "cmp('dloss_by_db1',dloss_by_db1, b1)\n",
    "\n",
    "# embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# dembcat_by_demb = \n",
    "# print(emb.shape) # 32 x 3 x 10\n",
    "# dembcat_by_demb = torch.ones(32,3,10)\n",
    "dloss_by_demb = dloss_by_dembcat.view(emb.shape)\n",
    "cmp('dloss_by_demb',dloss_by_demb,emb)\n",
    "# if u change emb by delta, the only way loss will change is by reshaping the loss of next step - embcat\n",
    "# print(dloss_by_dembcat.shape) # 32 x 30\n",
    "\n",
    "# emb = C[Xb] # embed the characters into vectors\n",
    "# demb_by_C = \n",
    "# print(C.shape) # 27 x 10\n",
    "\n",
    "dloss_by_dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dloss_by_dC[ix,:] += dloss_by_demb[k,j,:]\n",
    "\n",
    "cmp('dloss_by_dC',dloss_by_dC,C)\n",
    "        \n",
    "# print(Xb.shape) # 32 x 3\n",
    "# print(dloss_by_demb.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b643a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss_by_dlogits | exact: False | approximate: True  | maxdiff: 5.122274160385132e-09\n"
     ]
    }
   ],
   "source": [
    "# logits = h @ W2 + b2 # output layer\n",
    "# # cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# print('probs', logprobs.shape)\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# dloss_by_dlogits?\n",
    "# logits.shape\n",
    "sub1 = torch.zeros(32,27)\n",
    "sub1[range(n),Yb] = 1\n",
    "dloss_by_dlogits = (torch.exp(logits)/torch.exp(logits).sum(1, keepdim=True) - sub1)\n",
    "dloss_by_dlogits = dloss_by_dlogits/n\n",
    "\n",
    "cmp('dloss_by_dlogits',dloss_by_dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93282262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0024,  0.0028,  0.0006,  0.0015,  0.0006,  0.0024,  0.0008,  0.0011,\n",
      "        -0.0307,  0.0010,  0.0011,  0.0013,  0.0012,  0.0008,  0.0012,  0.0005,\n",
      "         0.0003,  0.0006,  0.0005,  0.0016,  0.0016,  0.0006,  0.0008,  0.0022,\n",
      "         0.0017,  0.0008,  0.0007], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAGdCAYAAADOsbLyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAp9ElEQVR4nO3df3DU9b3v8dfuZrMhvzYG8oOUoIAUVH60pRIzWkolhx9nxivKdNQ6c9DrwYEGb4Favem1Wj2nE6sz/qgH8d4ZD0xnRFtnilydc3AUS7hWoBWhiGgEiiUKCRibH2zIr93v/cNj2gji5w2b5kPyfMzsDCRv3/nsfndffN3s5/0NBUEQCADglfBgLwAAcCrCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYAD2UM9gI+L5VK6ciRI8rLy1MoFBrs5QBA2gRBoPb2dpWVlSkcPvO5sXfhfOTIEZWXlw/2MgBgwDQ0NGjMmDFnrBmwcF69erUefvhhNTY2avr06XriiSc0c+bML/3v8vLyJEmvbC9RTq7buy7RUMp5Xe93j3KulaR45KRzbWtyhKn32OhfnGs/6o2bemco6Vz7b1+/1NS7etd7pvqQ3I9PxHAsrbqCqKk+Fupxrj2Rsh37ZOD+jmI01GvqnTK+Wzkq0m6qt/gkmeNcaz32oyNtzrVdgS3qPkllm+pddZxI6r9f9X5fzp3JgITzr371K61atUpPPfWUKioq9Nhjj2nevHmqr69XcXHxGf/bz97KyMkNKzfPNZzd15bdHXEvlpQTcX+i9yRtvXOj7r2ze229LTGUEbKFVnaebS1huR+gyAC+lRUJbOvOMoRFKmXrbQtn2/gbazhbnuNWnYbXhPXY5xrWnWF4vCWp03g8rVzesh2Qo/LII49oyZIluvXWW3XppZfqqaeeUnZ2tv793/99IH4cAAw5aQ/n7u5u7dy5U1VVVX/9IeGwqqqqtG3btlPqu7q61NbW1u8GAMNd2sP5448/VjKZVElJSb+vl5SUqLGx8ZT62tpaxePxvhu/DAQADz7nXFNTo9bW1r5bQ0PDYC8JAAZd2n8hOGrUKEUiETU1NfX7elNTk0pLS0+pj8ViisVi6V4GAJzX0n7mnJmZqRkzZmjz5s19X0ulUtq8ebMqKyvT/eMAYEgakI/SrVq1SosXL9Y3v/lNzZw5U4899pgSiYRuvfXWgfhxADDkDEg433DDDTp+/LjuvfdeNTY26mtf+5o2bdp0yi8JAQCnF/LtAq9tbW2Kx+N69e1y5ThuQkkZPmBeluG+40+SGnrddwolUgP33nmncXdbfrjTubYtlWXqbd3JVRDucK5NGt9psxz7RJBp6v1v077hXHv329tNvS3H03rsw4YdmZKUZdgJaV2LhXXzTFmG+w7bRuMOW8tj0iP3DSsd7Und+LV31draqvz8/DPWDvqnNQAApyKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ95dffszTb35ztfNs2wnbuyybeMcyAtxWrZYW2olKWx4TPKMvY8nv/zilH+rxXCxTMu2WUmKyH36gPV+Lt/zlnPtg5Pct3pL0pJ97zvXFkQSpt49xouZTs503wZ9PGnbAt88gBd4bTeMHbA+ryzb1AfqosScOQOAhwhnAPAQ4QwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB7ydrZGdrhLOWG32RqWffCFkROmdUQMl5m3zHmQbDMnLLMyJKkn5T4DIRpKmnpbHm9JygufdK61zoVImo5PyNR7ZNh9psXP9r9h6m2ZT2J9vK2P4Qe9uc61nyTdayUpbDg+T1421dT7+3vfdq61zr+wzLKxzNSJht3XwZkzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA95u3378emXKSPktm112f4Dzn0tl1O3sm6bLQh3GHq7bWX/TCIVc64tjrSbelu2Y0tSMnA/B7BuVbY8honAfUu7ZNvWfkXMdnz+b8K9fqRx5EDSeM6VKff7aT327akRzrWW7diSlDLcz5xQl6m35bmSZ9gabhmUwJkzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA8RzgDgIW9na/zgj+8oJ882r8BFTqjbVG+Zr5BUyNT7eDLPfR2mXfm2eQwtqWxTb+v8i0LDWjqTtt6WtWSFeky9Lc+V33UO3EupOZlrqrfOePk/kyc61658f6+pdzTU61xrfW1anreWGR+SND76saG3+xyOiNzncHDmDAAeSns4//SnP1UoFOp3mzx5crp/DAAMaQPy/2KXXXaZXn311b/+kAxv3z0BAC8NSGpmZGSotLR0IFoDwLAwIO8579+/X2VlZRo/frxuvvlmHT58+Atru7q61NbW1u8GAMNd2sO5oqJC69at06ZNm7RmzRodOnRI3/rWt9TefvqrbdTW1ioej/fdysvL070kADjvpD2cFyxYoO9+97uaNm2a5s2bp//4j/9QS0uLfv3rX5+2vqamRq2trX23hoaGdC8JAM47A/6buoKCAn31q1/VgQOnv85fLBZTLOZ+vTsAGA4G/HPOJ06c0MGDBzV69OiB/lEAMGSkPZzvvPNO1dXV6YMPPtAbb7yh6667TpFIRDfddFO6fxQADFlpf1vjww8/1E033aTm5mYVFRXpqquu0vbt21VUVGTqEw93Kjfs9m/HBz2jnPuOjHaY1vFB70jnWuv24GTg/m9jUcbpf6H6RVKG3tbL3T9+6ddN9cve3uNcmxO2XcLeslU5kbK9fWbZ8ntRRrOpd1HmcefaI73u2/wl6ZhhLIBk25JtHVFg3ZJtETZshba+Nht6C5xrIwqcaztS7mMY0h7Ozz33XLpbAsCww2wNAPAQ4QwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB7y9uJ+HUGmQo7zISyzIT5Kxk3ruCqrybl2R5f7HA5JGhk54VzbknS/DLwkXRRtca5t6M039b51z7um+syQ+zwB6yXsLfMViiO2+ST3jZ/hXLtsv6m1iWUGi2R7vCWpPKPFufYj43MlHHI/Ph3G2SeWeRmdQdTU2/LatPTOMBwbzpwBwEOEMwB4iHAGAA8RzgDgIcIZADxEOAOAhwhnAPAQ4QwAHiKcAcBDhDMAeMjb7dsRpRRxrE0Z/o3pCWx3+Y/d7ttVE8btp09cNt259ifvbjP1trA+JtbLzFtkh7pM9RHD9uBjyTxT79vf/5NzrWUbuVVBpMNU35bKMtVHDY+h5fGWpNJIwrm2IXB9xf/XWhS41xrXfTzp/rq3PGeTgfuaOXMGAA8RzgDgIcIZADxEOAOAhwhnAPAQ4QwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA85O1sjROpLKVSbnvtH734Eue+PzzwjmkdlnkZ+eFOU+8f7XtzQNYhSe2pEc61k6LNpt5NSffektSYjDvX5oVPmnpb5IRtczs6A8PMCcOcB0kqirQ71yaCTFNv6/18r7vIuXZsxl9Mvff3jHSutTwmknSk9wLn2mio19Tb8jy0vNZOBknnWs6cAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYAD3k7W6MziCocuM3WuO39Q859IyH3eQmSlB9yn5fRGURNvS2svS31f+p1n30hSdGQ+3yAT+vd5xpYZ4iUZrQ6136SzDX1zgl1O9dWZtnmWezqcntuS1KmbI/3yIhtPslHgfs5Ws0l3zb1/uc9+5xrjwTuszIk2/MqanwMewL3aDStw/Da4cwZADxkDuetW7fqmmuuUVlZmUKhkF544YV+3w+CQPfee69Gjx6tESNGqKqqSvv370/XegFgWDCHcyKR0PTp07V69erTfv+hhx7SL37xCz311FPasWOHcnJyNG/ePHV22sZpAsBwZn7PecGCBVqwYMFpvxcEgR577DHdc889uvbaayVJv/zlL1VSUqIXXnhBN95447mtFgCGibS+53zo0CE1Njaqqqqq72vxeFwVFRXatm3baf+brq4utbW19bsBwHCX1nBubGyUJJWUlPT7eklJSd/3Pq+2tlbxeLzvVl5ens4lAcB5adA/rVFTU6PW1ta+W0NDw2AvCQAGXVrDubS0VJLU1NTU7+tNTU193/u8WCym/Pz8fjcAGO7SGs7jxo1TaWmpNm/e3Pe1trY27dixQ5WVlen8UQAwpJk/rXHixAkdOHCg7++HDh3S7t27VVhYqLFjx2rFihX613/9V02cOFHjxo3TT37yE5WVlWnhwoXpXDcADGnmcH7zzTf1ne98p+/vq1atkiQtXrxY69at01133aVEIqHbb79dLS0tuuqqq7Rp0yZlZWWZfk401KtoyO1y81mhHue+1m3QT9z0XefaJc9sNPX+SkaHc21RNGHq/Uky27k2bNzS3mHcYm3ZChuWbS2Nhq3n1q37x5J5zrUbE+61kpQTdt/ubXl+S1Jjj207flHE/RNSNfu2m3p3ptxfb9bXpuVxicgtS/7KfZt1S8r9tdYThJxrzeE8e/ZsBcEX39FQKKQHHnhADzzwgLU1AOC/DPqnNQAApyKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ+bt238vySCspOMl23sM/8ZY5ghI0tL1G5xrzTMQku4zECaGj5t6Wzz4tVmm+v+1e4upvjsZca61zJyQ5PwckaSU8Vwk03AZ+4Kw+5wUSSqKuM9KaU6NMPXOC5801Tcnc51r88MDdy3QyzKPmep3d5U511rnqlhey9FQr6HW/TnFmTMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYAD3m7fTsSSikScruMeKbhMubWS6SH5b7t03pp94symp1rG3oLTL0ta/kfb+0w9U4a/023bIW1bMeWpOLICefaZsMl7CXp8WkznGtr9r5h6m05npbtwZJUanhMJOm9ZI5zbbZxe31L7wXOtW93l5p6W7apW7fuW56z3YH7eIIMQ1Zx5gwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHjI29ka8fBJ5YTd/u1oMcxMsNRKUnGk3bm2MRk39T5muCS9ZcaHJJVGWk31FtYZIhZZYfeZBpJUc9l3nGvvfNs2Q2T5nreca9tTWabelhkihcZZGdY5LEUZbc61KePsE8varY+hZV6GZf6FtT4Scn9tWqakcOYMAB4inAHAQ4QzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8BDhDAAeIpwBwEPebt9+eOZMZYQynWrv2/c7575txi2ix5J5zrXWLdYXRVucaz/oKTD1bk65X+4+osDUOzvcZaqPKGSotT2G979T51x7pPcCU++skPtWcuuW9rzwSefaxl7bWADLyAHJNnYgO2Q79pbHxfJ4S1JBpGNA1iFJHamYc61lq3cycH+tceYMAB4inAHAQ+Zw3rp1q6655hqVlZUpFArphRde6Pf9W265RaFQqN9t/vz56VovAAwL5nBOJBKaPn26Vq9e/YU18+fP19GjR/tuzz777DktEgCGG/MvBBcsWKAFCxacsSYWi6m0tPSsFwUAw92AvOe8ZcsWFRcXa9KkSVq2bJmam5u/sLarq0ttbW39bgAw3KU9nOfPn69f/vKX2rx5s37+85+rrq5OCxYsUDKZPG19bW2t4vF43628vDzdSwKA807aP+d844039v156tSpmjZtmiZMmKAtW7Zozpw5p9TX1NRo1apVfX9va2sjoAEMewP+Ubrx48dr1KhROnDgwGm/H4vFlJ+f3+8GAMPdgIfzhx9+qObmZo0ePXqgfxQADBnmtzVOnDjR7yz40KFD2r17twoLC1VYWKj7779fixYtUmlpqQ4ePKi77rpLF198sebNm5fWhQPAUBYKAsNmb336SYzvfOfUy9EvXrxYa9as0cKFC7Vr1y61tLSorKxMc+fO1b/8y7+opKTEqX9bW5vi8bie3z1Z2Xlue9aThtkN4zM+ca6VpKZkrnOtdTaAZd3Hk7a3eyxrsV423mpk5IRz7QMTZph633Vgj3Ot9fjkhbuda3sC2/+ENvQWmuotoqFeU31OyP1+WmdUWOqtz0PLDBHrTJ38cKdzrWXWTKI9paqpDWptbf3St3DNZ86zZ8/WmfL85ZdftrYEAHwOszUAwEOEMwB4iHAGAA8RzgDgIcIZADxEOAOAhwhnAPAQ4QwAHiKcAcBDhDMAeCjt85zTZc2VX1dGKNOp9pF3XnHuezyVbVqHZR5DInBb72eShnkM1nkJZRmtzrUNvQWm3j2B7WmTY3gMl72/39TbMrshkYqZeifV4VzbYextYZ0JYp1/EQ2730/rjIoCQ2/r68e6loESkft4orCpFgDgHcIZADxEOAOAhwhnAPAQ4QwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA85O327dte36PsPLdLpdf3FDv3LYq0mdbRmIw71w7kNtuJ0eOm3seTOc61RYZLzEtSj/ES9od7L3CuzQufNPW2bIGPhNy3zkrSJ8lc51rLNmVJKs9oca5tTo0w9Y4Gtq3+zYb7mR/uNPXuNjxXJkc/NvXe3VXmXBsJpUy9La/N2glfd67tDXokfehUy5kzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA8RzgDgIW9na0RCKUVCIbdiw8gE62XjLcKy7d/PDnU51/YYZkhIUjTkPl+h3XiJ+YcnzzDVr3p3l3NtNJQ09c4JdTvXJuX4fPovnUn350oiyLT17nXvbZlPIUmZxsdwomGmxfFUtql3yvB6+6DXfY6NJBVluM/J6UjFTL0tz5WV7+91X0d7Ulu+5lbLmTMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYAD3m7fbsw3KGcsNu/HR/1XuDcN2HbYa288Enn2p7A9nBatlg3JvMHrHdWqMfU+/v73LerStLISMK5tiU1wtTbslW5OZlr6l0Q7nCuLTLcR0k62DPSVG9hOfaS9Ilh+35L0rZ9OxJyf8EljaMVLKMYorJtaX98+kzn2rv3bHOuTRqer5w5A4CHTOFcW1uryy+/XHl5eSouLtbChQtVX1/fr6azs1PV1dUaOXKkcnNztWjRIjU1NaV10QAw1JnCua6uTtXV1dq+fbteeeUV9fT0aO7cuUok/vq/dCtXrtSLL76o559/XnV1dTpy5Iiuv/76tC8cAIYy05ukmzZt6vf3devWqbi4WDt37tSsWbPU2tqqp59+WuvXr9fVV18tSVq7dq0uueQSbd++XVdccUX6Vg4AQ9g5vefc2toqSSosLJQk7dy5Uz09PaqqquqrmTx5ssaOHatt207/pnlXV5fa2tr63QBguDvrcE6lUlqxYoWuvPJKTZkyRZLU2NiozMxMFRQU9KstKSlRY2PjafvU1tYqHo/33crLy892SQAwZJx1OFdXV2vv3r167rnnzmkBNTU1am1t7bs1NDScUz8AGArO6nPOy5cv10svvaStW7dqzJgxfV8vLS1Vd3e3Wlpa+p09NzU1qbS09LS9YrGYYjHbJWQAYKgznTkHQaDly5drw4YNeu211zRu3Lh+358xY4ai0ag2b97c97X6+nodPnxYlZWV6VkxAAwDpjPn6upqrV+/Xhs3blReXl7f+8jxeFwjRoxQPB7XbbfdplWrVqmwsFD5+fm64447VFlZySc1AMDAFM5r1qyRJM2ePbvf19euXatbbrlFkvToo48qHA5r0aJF6urq0rx58/Tkk0+mZbEAMFyEgiAIBnsRf6utrU3xeFxX592sjJDb5eZ//vYrzv07Urb9+91yvyy9de5AaUarc+0nxrkQlnkZicDtcf6MdYZIUcT945HtxtkalkvYR2R7qltnjli0GeZZ5IS7TL0TKdvvcCZGP3au3dd9+t8dfRHL2i2zMqSBPT4Wllkmifakrpt+QK2trcrPP/O8HGZrAICHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA8RzgDgIcIZADxEOAOAhwhnAPDQWY0M/Xu4betuZee5bZ3+0UXuQ5Xu/dNbpnVYtk1bt5Me6b3AuXZi9Lip9/FkjnNtUaTd1LsncN/SLknNhsfQulU5HLifX6SM5yItKfft+AXhDlPvCdFm59pm45Z262O4v2eUc+3IyAlT727Dc2Vq5ukvyPFFdneVOddGQilTb8tr2bLtvMvwfOXMGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8JC3szUKIwnlRNL/b0e7cU5B0rAXviBim6/QnHKff9FpnGdhmWmQSOaZeltniPhyCfuwbPMVLPMyoqFeU++kQs617aksU++okqZ6y8wRy7wRyfaYZ7s/JJJs8zIKjTNBOlIx59qewD1GewL3O8mZMwB4iHAGAA8RzgDgIcIZADxEOAOAhwhnAPAQ4QwAHiKcAcBDhDMAeIhwBgAPebt9O5HKlFJuW5Af++AN575/6i00raMoo8251rIdW5KKIu3OtY3JfFPvJyZPca5d8d7bpt6W7aqSdGlms3Pt7q5iU+/MkPtW5YRhS64kFUQSzrVtyVxT72bDDmvL9mpJ6gwyTfVZ4W733ilb77Bhi/UbnWWm3v8t5y/Otdu6bOMPLNvrSyOtzrWJiPvjwZkzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA8RzgDgIW9na5RknFBuhtu/HZZ5Gda5EC1J90vBW+Y8SNLIcJdzreVS7ZK06r0/OtdaZzdYLncvSe91X+BcO9J4CXsL67otszisz6u88Enn2s4gaur9v2d83VT/zzvdnyuWORySlAzcn1sXRT829d7W5T7nIyvUY+pteUl81Ov+/O7oTUr6c7qXAAD4ezGFc21trS6//HLl5eWpuLhYCxcuVH19fb+a2bNnKxQK9bstXbo0rYsGgKHOFM51dXWqrq7W9u3b9corr6inp0dz585VItF/tOKSJUt09OjRvttDDz2U1kUDwFBneqNs06ZN/f6+bt06FRcXa+fOnZo1a1bf17Ozs1VaWpqeFQLAMHRO7zm3tn46ZLqwsP8v5J555hmNGjVKU6ZMUU1NjTo6Or6wR1dXl9ra2vrdAGC4O+tPa6RSKa1YsUJXXnmlpkz561U3vve97+nCCy9UWVmZ9uzZo7vvvlv19fX6zW9+c9o+tbW1uv/++892GQAwJJ11OFdXV2vv3r16/fXX+3399ttv7/vz1KlTNXr0aM2ZM0cHDx7UhAkTTulTU1OjVatW9f29ra1N5eXlZ7ssABgSziqcly9frpdeeklbt27VmDFjzlhbUVEhSTpw4MBpwzkWiykWs32GFwCGOlM4B0GgO+64Qxs2bNCWLVs0bty4L/1vdu/eLUkaPXr0WS0QAIYjUzhXV1dr/fr12rhxo/Ly8tTY2ChJisfjGjFihA4ePKj169frH//xHzVy5Ejt2bNHK1eu1KxZszRt2rQBuQMAMBSZwnnNmjWSPt1o8rfWrl2rW265RZmZmXr11Vf12GOPKZFIqLy8XIsWLdI999yTtgUDwHBgflvjTMrLy1VXV3dOC/pMaypLvan07y6PhnpN9Z0p9/37+eFOU+/3ekY5106MNpt6H+nNc67tNMw/kKRHp11uql/2x93OtTlynzdiZZ0hYp2VYlEQ+eKPl37eJ8lcU+8f7Pq9qd4yc6RHEVNvy0yLCzNs8y9e73SfqZMdsj2vrM+VgTD4KwAAnIJwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYAD531POeBdjKVqVDKbatoRGfeVv63LJekl6QHJl7iXPvD/XtNvS0aevNN9T2B+6G1Xjb+nr2vf3nR32hJZTvXtqdGmHpbtuNbtilLtu3bhZETpt6dQdS5Njs8cFvaJdv28Eszm0y993WXuNf25Jh6Jw1jBzpkG0tsyYmiDPfjk8hwfw5y5gwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHjI29kaxZF25Ubc/u1oMcxjOJ60zaiofr/eVG+x+psVzrV37fx/tuaGmRPNhtkKkpQV7jbV54U7nWs7UrYZCJYZFZZZDJKUMpy7dCfd5sB8pjSj3bm2obfA1Lso4t5bss0n+aDHthbr3BaLr2T8xbk2apiTIkkf9Iwy9HZ//DqS7uvgzBkAPEQ4A4CHCGcA8BDhDAAeIpwBwEOEMwB4iHAGAA8RzgDgIcIZADxEOAOAh7zdvn00ma9sxy2xPYH73cgODdxl5nOMl7Bf+oc/ONdatkBLUnPS/TLzE6LHTb3/58QrTfUr3nvbudayFVaSZDj20QHcSlwcOWGqb+zNc66NKDD1bklmm+otMo3boNtS7tvrC2Tr/VHvBc611tdmaUaLc61lhIDCbN8GgPMa4QwAHiKcAcBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ97O1vjfFVOVEXLbs/7jd3c4921PZZnWURppG7DeBZEO51rLrAyrxmS+qf777+4z1VvmZZjmFMg2V8U6t6MzlelcGwmlTL0twrL1ts6/yDHMm7HO+UiE3B/DY0n3eSOSfSaMxWHD3A7L490bhJxrOXMGAA+ZwnnNmjWaNm2a8vPzlZ+fr8rKSv3nf/5n3/c7OztVXV2tkSNHKjc3V4sWLVJTU1PaFw0AQ50pnMeMGaMHH3xQO3fu1Jtvvqmrr75a1157rd555x1J0sqVK/Xiiy/q+eefV11dnY4cOaLrr79+QBYOAEOZ6T3na665pt/ff/azn2nNmjXavn27xowZo6efflrr16/X1VdfLUlau3atLrnkEm3fvl1XXHFF+lYNAEPcWb/nnEwm9dxzzymRSKiyslI7d+5UT0+Pqqqq+momT56ssWPHatu2bV/Yp6urS21tbf1uADDcmcP57bffVm5urmKxmJYuXaoNGzbo0ksvVWNjozIzM1VQUNCvvqSkRI2NjV/Yr7a2VvF4vO9WXl5uvhMAMNSYw3nSpEnavXu3duzYoWXLlmnx4sXat8/20aq/VVNTo9bW1r5bQ0PDWfcCgKHC/DnnzMxMXXzxxZKkGTNm6A9/+IMef/xx3XDDDeru7lZLS0u/s+empiaVlpZ+Yb9YLKZYLGZfOQAMYef8OedUKqWuri7NmDFD0WhUmzdv7vtefX29Dh8+rMrKynP9MQAwrJjOnGtqarRgwQKNHTtW7e3tWr9+vbZs2aKXX35Z8Xhct912m1atWqXCwkLl5+frjjvuUGVlJZ/UAAAjUzgfO3ZM//RP/6SjR48qHo9r2rRpevnll/UP//APkqRHH31U4XBYixYtUldXl+bNm6cnn3zyrBZ21x9+r5w8txP7lpT7peC/Emk1rcOyjXNsxl9MvS3bpruDiKm3ZTuxZQu0JBUZtrRLUntqhHNtVLatx5GQ+3Ziy1Z8SWoJua/bKifc6VzbLduxr73UdjL0z3vcf2dUmtFi6p1Iub9leVH0Y1Nvy2szZXyTINuwpd0ycqDbsPvd9Kp8+umnz/j9rKwsrV69WqtXr7a0BQB8DrM1AMBDhDMAeIhwBgAPEc4A4CHCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ95dfTsIPt3fmDjhvv24I+W+5fdExHYl445eQ+8MY++ke2/Ltk/Jun3b/YrAkpSwPoaG4xMyXmk6MFwN2nrsE4Z1WyUNx6dbtuPTG3Sb6jva3e9nwvocN7x+EtGB650yXjU8MFxRuytwP8ftOPFp389y7kxCgUvV39GHH37IwH0AQ1pDQ4PGjBlzxhrvwjmVSunIkSPKy8tTKPTXM4a2tjaVl5eroaFB+fnuA4PON9zPoWM43EeJ+2kRBIHa29tVVlamcPjMZ9zeva0RDofP+C9Kfn7+kH4CfIb7OXQMh/socT9dxeNxpzp+IQgAHiKcAcBD5004x2Ix3XfffUP+eoPcz6FjONxHifs5ULz7hSAA4Dw6cwaA4YRwBgAPEc4A4CHCGQA8dN6E8+rVq3XRRRcpKytLFRUV+v3vfz/YS0qrn/70pwqFQv1ukydPHuxlnZOtW7fqmmuuUVlZmUKhkF544YV+3w+CQPfee69Gjx6tESNGqKqqSvv37x+cxZ6DL7uft9xyyynHdv78+YOz2LNUW1uryy+/XHl5eSouLtbChQtVX1/fr6azs1PV1dUaOXKkcnNztWjRIjU1NQ3Sis+Oy/2cPXv2Kcdz6dKlaV/LeRHOv/rVr7Rq1Srdd999euuttzR9+nTNmzdPx44dG+ylpdVll12mo0eP9t1ef/31wV7SOUkkEpo+fbpWr1592u8/9NBD+sUvfqGnnnpKO3bsUE5OjubNm6fOzs6/80rPzZfdT0maP39+v2P77LPP/h1XeO7q6upUXV2t7du365VXXlFPT4/mzp2rRCLRV7Ny5Uq9+OKLev7551VXV6cjR47o+uuvH8RV27ncT0lasmRJv+P50EMPpX8xwXlg5syZQXV1dd/fk8lkUFZWFtTW1g7iqtLrvvvuC6ZPnz7YyxgwkoINGzb0/T2VSgWlpaXBww8/3Pe1lpaWIBaLBc8+++wgrDA9Pn8/gyAIFi9eHFx77bWDsp6BcuzYsUBSUFdXFwTBp8cuGo0Gzz//fF/Nu+++G0gKtm3bNljLPGefv59BEATf/va3gx/84AcD/rO9P3Pu7u7Wzp07VVVV1fe1cDisqqoqbdu2bRBXln779+9XWVmZxo8fr5tvvlmHDx8e7CUNmEOHDqmxsbHfcY3H46qoqBhyx1WStmzZouLiYk2aNEnLli1Tc3PzYC/pnLS2tkqSCgsLJUk7d+5UT09Pv+M5efJkjR079rw+np+/n5955plnNGrUKE2ZMkU1NTXq6OhI+8/2bvDR53388cdKJpMqKSnp9/WSkhK99957g7Sq9KuoqNC6des0adIkHT16VPfff7++9a1vae/evcrLyxvs5aVdY2OjJJ32uH72vaFi/vz5uv766zVu3DgdPHhQP/7xj7VgwQJt27ZNkUhksJdnlkqltGLFCl155ZWaMmWKpE+PZ2ZmpgoKCvrVns/H83T3U5K+973v6cILL1RZWZn27Nmju+++W/X19frNb36T1p/vfTgPFwsWLOj787Rp01RRUaELL7xQv/71r3XbbbcN4spwrm688ca+P0+dOlXTpk3ThAkTtGXLFs2ZM2cQV3Z2qqurtXfv3vP+dyJf5ovu5+23397356lTp2r06NGaM2eODh48qAkTJqTt53v/tsaoUaMUiURO+a1vU1OTSktLB2lVA6+goEBf/epXdeDAgcFeyoD47NgNt+MqSePHj9eoUaPOy2O7fPlyvfTSS/rtb3/bb7RvaWmpuru71dLS0q/+fD2eX3Q/T6eiokKS0n48vQ/nzMxMzZgxQ5s3b+77WiqV0ubNm1VZWTmIKxtYJ06c0MGDBzV69OjBXsqAGDdunEpLS/sd17a2Nu3YsWNIH1fp06v9NDc3n1fHNggCLV++XBs2bNBrr72mcePG9fv+jBkzFI1G+x3P+vp6HT58+Lw6nl92P09n9+7dkpT+4zngv3JMg+eeey6IxWLBunXrgn379gW33357UFBQEDQ2Ng720tLmhz/8YbBly5bg0KFDwe9+97ugqqoqGDVqVHDs2LHBXtpZa29vD3bt2hXs2rUrkBQ88sgjwa5du4I///nPQRAEwYMPPhgUFBQEGzduDPbs2RNce+21wbhx44KTJ08O8sptznQ/29vbgzvvvDPYtm1bcOjQoeDVV18NvvGNbwQTJ04MOjs7B3vpzpYtWxbE4/Fgy5YtwdGjR/tuHR0dfTVLly4Nxo4dG7z22mvBm2++GVRWVgaVlZWDuGq7L7ufBw4cCB544IHgzTffDA4dOhRs3LgxGD9+fDBr1qy0r+W8COcgCIInnngiGDt2bJCZmRnMnDkz2L59+2AvKa1uuOGGYPTo0UFmZmbwla98JbjhhhuCAwcODPayzslvf/vbQNIpt8WLFwdB8OnH6X7yk58EJSUlQSwWC+bMmRPU19cP7qLPwpnuZ0dHRzB37tygqKgoiEajwYUXXhgsWbLkvDuxON39kxSsXbu2r+bkyZPB97///eCCCy4IsrOzg+uuuy44evTo4C36LHzZ/Tx8+HAwa9asoLCwMIjFYsHFF18c/OhHPwpaW1vTvhZGhgKAh7x/zxkAhiPCGQA8RDgDgIcIZwDwEOEMAB4inAHAQ4QzAHiIcAYADxHOAOAhwhkAPEQ4A4CHCGcA8ND/ByLVHs1eISuGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dloss_by_dlogits.detach())\n",
    "print(dloss_by_dlogits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e873e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hprebn = embcat @ W1 + b1 # hidden layer pre-activation 32 examples x 64 output neurons(32 egs x 30 emb   x   30 x 64 = 32 egs x 64)\n",
    "\n",
    "# # BatchNorm layer\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True) # 1 x 64\n",
    "\n",
    "# bndiff = hprebn - bnmeani # 32 x 64 - 1 x 64(broadcast 64 times) = 32 x 64\n",
    "# bndiff2 = bndiff**2 # squaring each term - 32 x 64\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) # 1 x 64\n",
    "\n",
    "# print('bnvar ',bnvar.shape) \n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "hprebn.shape\n",
    "# bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## BIGGEST misconception\n",
    "# batch normalization is to normalize outputs of a single neuron for all batches\n",
    "# basically you take mean across all batches, NOT across all neurons\n",
    "# hence its called batch normalization, makes sense only when neural network is trained batch wise.\n",
    "\n",
    "# 64 neurons, 32 batches, u take average across 32 batches and get 1 x 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
