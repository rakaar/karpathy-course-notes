{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e m\n",
      "m m\n",
      "m a\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip('emma','mma'):\n",
    "  print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_index(c):\n",
    "  if c == '<S>':\n",
    "    return 26\n",
    "  elif c == '<E>':\n",
    "    return 27\n",
    "  else:\n",
    "    return ord(c) - 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "N = torch.zeros((28,28), dtype=torch.int32)\n",
    "\n",
    "for word in words:\n",
    "  chs = ['<S>'] + list(word) + ['<E>'] \n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    N[give_index(ch1),give_index(ch2)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f171ac74710>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVJElEQVR4nO3de3Dc1XUH8O/ZXUm2ZFnYlixU27ydpE5IDVVcl9AMLW0CTqeGtGXizqTuDFPzR9IhM/mjDH2EzrRT2mlI05lOWlNcnE5KShsYmIbyiEvqSQsugtjG2ICN8UNGlvBTsrEe+9vTP3YpCuieI+9v97cb3+9nxqPVnr2/e7W7x/s4v3uvqCqI6MKXa/QAiCgbTHaiSDDZiSLBZCeKBJOdKBKFLDtrzc/VuYX54Ru4hYHwDbTF/lMkKdlHnpyy2xuxqe52s21uyv7D8qfPmXE4f9vkRa3BWGHC7rtzyRkzfma383pg3TGA+ZhOLO0wm7adtB8zKSZ234kRLzhP/YlJO+4oLrSfE4XTE8GYFotm26s+fjYYO3S4iGMnkhkflVTJLiI3AfgGgDyAf1DVe63bzy3Mx3UX/1b4Bl4Z0LgTkqU9ZtPcqfAdBAClw2+ZcZHws3r4N68x2857y35Sdjy104znerrN+OCvXxKMXfSG/cS54U//24w/f80cMy45O9u1FH5M99+5ymx7xSP2Y5Y/NmbGcWo0HFu8yGyq+w/Zx3ac+FX7ObHoqTeCsWR4xGz76H/8bzD2qZuPBmNVv40XkTyAvwVwM4AVANaJyIpqj0dE9ZXmM/sqAPtUdb+qTgL4DoC1tRkWEdVammRfAuDwtN8HK9f9GBHZICIDIjIwmTifTYmobur+bbyqblTVflXtb83PrXd3RBSQJtmPAFg27felleuIqAmlSfYXACwXkctFpBXA5wE8XpthEVGtSZpZbyKyBsBfo1x626Sqf2bdvqvQoz/fdWswnpw6ZXdojTWXN5sWLl1qxotvHrT7thhlOQDItds119JZu8Tkdm/UjL2abZpjpz1+fsWHzHiy+/Wqjw3AflzqPNuznvebtITPq3h+6kmMlo7Xvs6uqk8AeCLNMYgoGzxdligSTHaiSDDZiSLBZCeKBJOdKBJMdqJIZDqfHS0F4GJjuubJk3Z7q25acuY2T6WrN1sKl19qxvXYiVTHz1/UZcZLZ+s35yDn9J0cO171sZNXw9M8Z8U5v+GCpdY8//D5A3xlJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSmZbetCWPyd7OYDy/xztAuKwgbW1m08krF5vx3GD1624kzsq0+WU/ZR9g1FgFFUBy6rTd3pre28TlqXyPvcJrMvK2fQBnmmo9p/56cvPsZbLdx9SQ7w0/l2W4JTymqnskop8oTHaiSDDZiSLBZCeKBJOdKBJMdqJIMNmJIpFpnV0mi2g7FJ7umRhL5AIAjB1Dc53zzKbOBFh36V+I8f+it5NpW7j2WW5vL4Oda7Xb7/uT8I6hyzfZterDa+3zD5b93S4znmbJ5BO/fIXZduH2BXbfo/YS3MUjQ8FY4eJeu62zk6oU7MektDy8sy4A5F7eG247Pm62ffUvwmMf/8Pw48FXdqJIMNmJIsFkJ4oEk50oEkx2okgw2YkiwWQnikSqLZvPV1e+W1fP+7VgvDQ2Vre+rW1uAUCLU/YBUtxPuTlzzLhXV20o5xwAdwlvg/uYTE1WfewLmXVuw/PFpzBaOlH7LZtF5ACAMZTPWSmqan+a4xFR/dTiDLpfVNVjNTgOEdURP7MTRSJtsiuAp0XkRRHZMNMNRGSDiAyIyMCkNvFnU6ILXNq38der6hERWQzgGRF5VVW3Tr+Bqm4EsBEof0GXsj8iqlKqV3ZVPVL5OQLgUQCrajEoIqq9qpNdRDpEpPPdywA+DcCeD0lEDZPmbXwvgEelvC55AcA/q+qTZgsRf954nbjreHvbRRvyixaacT1X5+8qrLXhvfMDnHXlxZurb+0e7JAWby68c+6Dd/x8+ByBeq8b767Xn+b8FmttBYT7rTrzVHU/gJ+ptj0RZYulN6JIMNmJIsFkJ4oEk50oEkx2okhkWgebWjAHI5/7SDC+6P7n6ta3LOiyb5Ci9JYcDy+PDQD55faSydi73447ZZzc3LnBmE45JSantJZztsJOnO2m68osQTlbNifO1NyUU79z7e1mvHTWXgbbMnxHeHJp8V+2BmN8ZSeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEkx2okhkO980BxTnhOu63tLC+cXdwZg3ZXHsantr4vZDg2Y8Z0xjLTl19tKbh8y4t1xzvmeRGZ9csTQYa91t/11vr7nSjC/+T7s9zjj1YmMOrFy+zGya9NjTktv2Ddvth8PbVec7O+22zvkD3lRtWdpnxvND4S2hvb5LxtPFOjuAr+xEkWCyE0WCyU4UCSY7USSY7ESRYLITRYLJThSJTLds7uxaqtde93vBeOtTA3XrO99r19mT4XDd0+Utx1xoMePNvDVxoe9iM14cOprRSM6fNae89M47GY6kxozzMrYlT2NUZ96yma/sRJFgshNFgslOFAkmO1EkmOxEkWCyE0WCyU4UiUzns2tOUOwI1wjt2ewp++6xt1VGijp7vmu+GZcOe1528chbVfcNAGKs7a4TE6mOrZP1OwfAW7/A2w/aW8OgdO7c+Q7pPSm3XM5322sQJMeOn++I3ju2sQeCnArnl/vKLiKbRGRERHZNu26hiDwjInsrPxec74CJKFuzeRv/IICb3nfdXQC2qOpyAFsqvxNRE3OTXVW3Anj/uktrAWyuXN4M4JbaDouIaq3az+y9qjpUuXwUQG/ohiKyAcAGAGide1GV3RFRWqm/jdfyTJrgtxWqulFV+1W1v6VtXtruiKhK1Sb7sIj0AUDlZ4opY0SUhWqT/XEA6yuX1wN4rDbDIaJ6cT+zi8hDAG4A0C0igwC+CuBeAA+LyO0ADgK4bTadJW3AqSvCdcD2FLVNq9YMAAc+Z9fZL9llhk3JqdNmfPi3P2rGe/8mXZ29eF34+Pn/2mE3Ljn7lHv72jtr5lu8efze2uzuevvG+Q/JaWdfee9+cZxdba/HP+ffq6+zT159WTCmA+E8cJNdVdcFQjd6bYmoefB0WaJIMNmJIsFkJ4oEk50oEkx2okhku2UzADFmBrpLLhenwjFnKufl/xrevhcA0hVabD0/SjHVchbyz74UjOXmzDHblsbtv1zOOEsupymXOqU1TZxHxZlmai4XnbK05unY+qoZT9N7297w8t0yHs4RvrITRYLJThQJJjtRJJjsRJFgshNFgslOFAkmO1Eksl1KOg9MdRpxZ8pjzliSWfrsLZkn+uzlngt7zDDy843pkqP2dMnxHnvJZHdqr9j/J+fmhKc1elsTj65bbcYX/uCAGfdq3WZTp46e7zSeLAAw1zmHwJp+60yPTVuHl/a5dtw4L8Q7Z+R7LzwRjK36THi6NV/ZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEqIp6qTna35uka5uu7n6A5SMudEtztzoKXt7X2uuvCfnLGNdmnSO7dV0nZpw4ZIl4UMfP2m2Pbr+ajPe+/cDZjzNtsryCbvv/Fv2csvJyDEznjPq8N5W1Jp4f5f9mErefszUeC57z4f8Rz8cjD237wGcPjc044kbfGUnigSTnSgSTHaiSDDZiSLBZCeKBJOdKBJMdqJIZFpn78p36+q5nw3GvbnXaeTa2814mr7dY4/b85PrvYZ5Kt68b6fOnmabbW9ed7SM9Q+2lb6PUT1RXZ1dRDaJyIiI7Jp23T0ickREtlf+ralq0ESUmdm8jX8QwE0zXP91VV1Z+RdeOoOImoKb7Kq6FYCxvg8R/SRI8wXdl0RkZ+Vt/oLQjURkg4gMiMjApI6n6I6I0qg22b8J4EoAKwEMAfha6IaqulFV+1W1v1XsBQKJqH6qSnZVHVbVRFVLAO4HsKq2wyKiWqsq2UWkb9qvtwLYFbotETUHd914EXkIwA0AukVkEMBXAdwgIisBKIADAO6YTWdaKtW1lm6pZ7+N+psyUcdzAOpdR7fOf7igH7MAN9lVdd0MVz9Qh7EQUR3xdFmiSDDZiSLBZCeKBJOdKBJMdqJIZLplc7GnAyO3XReML/7mc2Z7a3leabW3RT7zGXvZ4vZHt5lxa6qnt2zwgT/6WTN+6R87f3fBfphyC4JnK0PHxsy23hTn3FWXmfHkldfMuCXfa2+zrWNnqj52uQPjMXPuU2sJ7Fl1/eGrzHjy2r6qj138pWuDMd32P8EYX9mJIsFkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSmdbZC+dK6NlhTC10ar7WNrfqTFmct/e0GXcWRDaneia/8HGz6ZUPDpnxdBVdAMZUUa9e7MXltFPrNpY1LncQfsySt+0tmQuLu+1Dz59nxwfD93vaOrrH6jut/DljG2wjR/jKThQJJjtRJJjsRJFgshNFgslOFAkmO1EkmOxEkci0zo6SIjc+FQy7m0enWNZYJiarbutpPeRshTeVrqbr1YRLKersrtYWO55iy+/8gi4zXhwesdt794u3VXYdeesrSIrHrOXN4fBxJ8P5xVd2okgw2YkiwWQnigSTnSgSTHaiSDDZiSLBZCeKRKZ1djk3AXnljfANnLW8Tc7a7Xr4reqPDZjztosHB+2mztjcrr114+fOCca8efq5tjYzXtx/wDlCCsZa/ABQcNaVT47Z8+HN8zKcefjeY6aJfc5HcvKkGXfXAbCOfSJ8bC2Gx+W+sovIMhF5VkR2i8grInJn5fqFIvKMiOyt/AzvVEBEDTebt/FFAF9R1RUAVgP4ooisAHAXgC2quhzAlsrvRNSk3GRX1SFVfalyeQzAHgBLAKwFsLlys80AbqnTGImoBs7rQ7KIXAbgGgDbAPSq6rsLbR0F0BtoswHABgCYIx1VD5SI0pn1t/EiMg/AdwF8WVVHp8e0vDvgjDMiVHWjqvaran8r7C+DiKh+ZpXsItKCcqJ/W1UfqVw9LCJ9lXgfAHuKEhE1lPs2XkQEwAMA9qjqfdNCjwNYD+Deys/H3N5aWpDrm/HdPgCg+OZB9xDhxva0wPyypWa8dNgun5lTOdUuw8jHltuH3vmqHXf+tuSUvUy22daYagkA4pTm1Glv9n3smH2DFNNnXd6y5SmnBkuLPcVVp1JMuTbLfuG/azaf2T8J4AsAXhaR7ZXr7kY5yR8WkdsBHARw26wGSkQN4Sa7qv4QQOgMgBtrOxwiqheeLksUCSY7USSY7ESRYLITRYLJThSJbJeSTorQ487Uv3p1PfJ2Q/oFAH3tzYb17XKmmepk/ZbgrmsdvcG8KbB1O7Zxl/KVnSgSTHaiSDDZiSLBZCeKBJOdKBJMdqJIMNmJIpFpnV1LJZTeeSfLLt/ru571Yk8da64A7GWJvVq2tw12iiWPU/P6Fue1KsUW3y5vbOot4l09a/lvGQ+Pi6/sRJFgshNFgslOFAkmO1EkmOxEkWCyE0WCyU4UiUzr7MmiDhxf+4lgfOE/Pm+2l0JLMGZtW1y+gV0XdddeT1HLllZnDXFnjXJvy2a99qfDbXe8brYdW3uNGe96crcZT0ZHzbglf1GXfQNn7fWSty1yi7HmfclZNz7Nuu6Af36DtY6Ac37Ayd9YGYwVv/eDcJf2iIjoQsFkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSs9mffRmAbwHoRXlV6o2q+g0RuQfA7wJ4d0H2u1X1CbOzM0X0bDsRjCfentlG7TNx6qL57kVm3GWNzZnbLN45AM4cf7cO/6PXjLZTZtt5D9vnNpScWncayWmnRp92XXmrlp52rrt3boW3r32K9RUW/Nv2YKwwHn4uzeakmiKAr6jqSyLSCeBFEXmmEvu6qv7VeYyTiBpkNvuzDwEYqlweE5E9AJbUe2BEVFvn9ZldRC4DcA2AbZWrviQiO0Vkk4gsCLTZICIDIjIwmTRmSSoiOo9kF5F5AL4L4MuqOgrgmwCuBLAS5Vf+r83UTlU3qmq/qva35tvTj5iIqjKrZBeRFpQT/duq+ggAqOqwqiaqWgJwP4BV9RsmEaXlJruICIAHAOxR1fumXd837Wa3AthV++ERUa3M5tv4TwL4AoCXRWR75bq7AawTkZUol+MOALjDO9DUUuDon4fjC++71mxfbA9PCyy12uWv3IRdKmkfsP/fk86OcN/tdmlNxs6a8ZF1HzHj491mGL0vhMtrJz8UnhYMAL3P22PL7x00416JKRkeCcbe+az9eE902dtJdx6aMOP5rTvCMa8U65Q7S+fG7b577AettGh+OLZjj912PNy3GiXB2Xwb/0MAM2WSWVMnoubCM+iIIsFkJ4oEk50oEkx2okgw2YkiwWQnioRYdblamy8L9efkxsz6I4rNNt2CUT0x40knfGUnigSTnSgSTHaiSDDZiSLBZCeKBJOdKBJMdqJIZFpnF5G3ARycdlU3gGOZDeD8NOvYmnVcAMdWrVqO7VJV7ZkpkGmyf6BzkQFV7W/YAAzNOrZmHRfAsVUrq7HxbTxRJJjsRJFodLJvbHD/lmYdW7OOC+DYqpXJ2Br6mZ2IstPoV3YiygiTnSgSDUl2EblJRF4TkX0iclcjxhAiIgdE5GUR2S4iAw0eyyYRGRGRXdOuWygiz4jI3srPGffYa9DY7hGRI5X7bruIrGnQ2JaJyLMisltEXhGROyvXN/S+M8aVyf2W+Wd2EckDeB3ArwAYBPACgHWqujvTgQSIyAEA/ara8BMwRORTAM4A+Jaqfqxy3V8COKGq91b+o1ygqr/fJGO7B8CZRm/jXdmtqG/6NuMAbgHwO2jgfWeM6zZkcL814pV9FYB9qrpfVScBfAfA2gaMo+mp6lYAJ9539VoAmyuXN6P8ZMlcYGxNQVWHVPWlyuUxAO9uM97Q+84YVyYakexLABye9vsgmmu/dwXwtIi8KCIbGj2YGfSq6lDl8lEAvY0czAzcbbyz9L5txpvmvqtm+/O0+AXdB12vqtcCuBnAFytvV5uSlj+DNVPtdFbbeGdlhm3G/18j77tqtz9PqxHJfgTAsmm/L61c1xRU9Ujl5wiAR9F8W1EPv7uDbuVneOfEjDXTNt4zbTOOJrjvGrn9eSOS/QUAy0XkchFpBfB5AI83YBwfICIdlS9OICIdAD6N5tuK+nEA6yuX1wN4rIFj+THNso13aJtxNPi+a/j256qa+T8Aa1D+Rv4NAH/QiDEExnUFgB2Vf680emwAHkL5bd0Uyt9t3A5gEYAtAPYC+D6AhU00tn8C8DKAnSgnVl+DxnY9ym/RdwLYXvm3ptH3nTGuTO43ni5LFAl+QUcUCSY7USSY7ESRYLITRYLJThQJJjtRJJjsRJH4P2qh66VSyhNNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273, 0.0184,\n",
       "        0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029, 0.0512,\n",
       "        0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[26,:]\n",
    "p_first = N[26,:]/sum(N[26,:])\n",
    "p_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_char(num):\n",
    "    if num == 26:\n",
    "        c = '<S>'\n",
    "    elif num == 27:\n",
    "        c = '<E>'\n",
    "    else:    \n",
    "        c = chr(num + 97)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabrdarizero\n",
      "jaree\n",
      "leineton\n",
      "aa\n",
      "thisoydon\n",
      "lallyl\n",
      "m\n",
      "dryama\n",
      "haleyaxiioshuqus\n",
      "mbr\n"
     ]
    }
   ],
   "source": [
    "# generate 10 names by bigram\n",
    "for n in range(10):\n",
    "    name = ['<S>']\n",
    "    while True:\n",
    "        predicted_char = name[-1]\n",
    "        predicted_char_num = give_index(predicted_char)\n",
    "        p_first = N[predicted_char_num,:]/sum( N[predicted_char_num,:] )\n",
    "        ix = torch.multinomial(p_first, num_samples=1, replacement=True).item()\n",
    "        next_char = give_char(ix)\n",
    "        name.append(next_char)\n",
    "        if next_char == '<E>':\n",
    "            break\n",
    "    print(''.join(name[1:-1]))\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 names randomly\n",
    "\n",
    "# for n in range(1):\n",
    "#     name = ['<S>']\n",
    "#     while True:\n",
    "#         p_first = torch.ones(27)/27\n",
    "#         ix = torch.multinomial(p_first, num_samples=1, replacement=True).item()\n",
    "#         next_char = give_char(ix)\n",
    "#         name.append(next_char)\n",
    "#         print(next_char)\n",
    "#         if next_char == '<E>':\n",
    "#             break\n",
    "#     print(''.join(name[1:-1]))\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from N, get P using broadcasting\n",
    "# P = N.float()\n",
    "P = (N+1).float() # in data, we have some zeros, which give infinite negative log likelihood\n",
    "P /= P.sum(1, keepdims=True)\n",
    "P.shape\n",
    "P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6424e-02, 1.5982e-02, 1.3888e-02, 3.0755e-02, 2.0435e-02, 3.9808e-03,\n",
       "         4.9833e-03, 6.8794e-02, 4.8683e-02, 5.1898e-03, 1.6778e-02, 7.4573e-02,\n",
       "         4.8212e-02, 1.6038e-01, 1.8872e-03, 2.4474e-03, 1.7987e-03, 9.6276e-02,\n",
       "         3.2996e-02, 2.0287e-02, 1.1264e-02, 2.4622e-02, 4.7769e-03, 5.3962e-03,\n",
       "         6.0478e-02, 1.2856e-02, 2.9487e-05, 1.9582e-01],\n",
       "        [1.2046e-01, 1.4590e-02, 7.4822e-04, 2.4691e-02, 2.4542e-01, 3.7411e-04,\n",
       "         3.7411e-04, 1.5713e-02, 8.1556e-02, 7.4822e-04, 3.7411e-04, 3.8908e-02,\n",
       "         3.7411e-04, 1.8706e-03, 3.9656e-02, 3.7411e-04, 3.7411e-04, 3.1538e-01,\n",
       "         3.3670e-03, 1.1223e-03, 1.7209e-02, 3.7411e-04, 3.7411e-04, 3.7411e-04,\n",
       "         3.1425e-02, 3.7411e-04, 3.7411e-04, 4.3023e-02],\n",
       "        [2.2921e-01, 2.8090e-04, 1.2079e-02, 5.6180e-04, 1.5506e-01, 2.8090e-04,\n",
       "         8.4270e-04, 1.8680e-01, 7.6404e-02, 1.1236e-03, 8.9045e-02, 3.2865e-02,\n",
       "         2.8090e-04, 2.8090e-04, 1.0702e-01, 5.6180e-04, 3.3708e-03, 2.1629e-02,\n",
       "         1.6854e-03, 1.0112e-02, 1.0112e-02, 2.8090e-04, 2.8090e-04, 1.1236e-03,\n",
       "         2.9494e-02, 1.4045e-03, 2.8090e-04, 2.7528e-02],\n",
       "        [2.3606e-01, 3.6206e-04, 7.2411e-04, 2.7154e-02, 2.3244e-01, 1.0862e-03,\n",
       "         4.7067e-03, 2.1542e-02, 1.2219e-01, 1.8103e-03, 7.2411e-04, 1.1043e-02,\n",
       "         5.6119e-03, 5.7929e-03, 6.8610e-02, 1.8103e-04, 3.6206e-04, 7.6937e-02,\n",
       "         5.4308e-03, 9.0514e-04, 1.6836e-02, 3.2585e-03, 4.3447e-03, 1.8103e-04,\n",
       "         5.7567e-02, 3.6206e-04, 1.8103e-04, 9.3592e-02],\n",
       "        [3.3250e-02, 5.9655e-03, 7.5302e-03, 1.8825e-02, 6.2197e-02, 4.0585e-03,\n",
       "         6.1611e-03, 7.4813e-03, 4.0047e-02, 2.7383e-03, 8.7526e-03, 1.5887e-01,\n",
       "         3.7651e-02, 1.3085e-01, 1.3202e-02, 4.1074e-03, 7.3346e-04, 9.5790e-02,\n",
       "         4.2150e-02, 2.8409e-02, 3.4228e-03, 2.2688e-02, 2.4938e-03, 6.5033e-03,\n",
       "         5.2369e-02, 8.8993e-03, 4.8897e-05, 1.9481e-01],\n",
       "        [2.6045e-01, 1.0718e-03, 1.0718e-03, 1.0718e-03, 1.3290e-01, 4.8232e-02,\n",
       "         2.1436e-03, 2.1436e-03, 1.7256e-01, 1.0718e-03, 3.2154e-03, 2.2508e-02,\n",
       "         1.0718e-03, 5.3591e-03, 6.5380e-02, 1.0718e-03, 1.0718e-03, 1.2326e-01,\n",
       "         7.5027e-03, 2.0364e-02, 1.1790e-02, 1.0718e-03, 5.3591e-03, 1.0718e-03,\n",
       "         1.6077e-02, 3.2154e-03, 1.0718e-03, 8.6817e-02],\n",
       "        [1.6931e-01, 2.0460e-03, 5.1151e-04, 1.0230e-02, 1.7136e-01, 1.0230e-03,\n",
       "         1.3299e-02, 1.8465e-01, 9.7698e-02, 2.0460e-03, 5.1151e-04, 1.6880e-02,\n",
       "         3.5806e-03, 1.4322e-02, 4.2967e-02, 5.1151e-04, 5.1151e-04, 1.0332e-01,\n",
       "         1.5857e-02, 1.6368e-02, 4.3990e-02, 1.0230e-03, 1.3811e-02, 5.1151e-04,\n",
       "         1.6368e-02, 1.0230e-03, 5.1151e-04, 5.5754e-02],\n",
       "        [2.9369e-01, 1.1774e-03, 3.9246e-04, 3.2705e-03, 8.8305e-02, 3.9246e-04,\n",
       "         3.9246e-04, 2.6164e-04, 9.5500e-02, 1.3082e-03, 3.9246e-03, 2.4333e-02,\n",
       "         1.5437e-02, 1.8184e-02, 3.7677e-02, 2.6164e-04, 2.6164e-04, 2.6818e-02,\n",
       "         4.1863e-03, 9.4192e-03, 2.1847e-02, 5.2329e-03, 1.4390e-03, 1.3082e-04,\n",
       "         2.7996e-02, 2.7473e-03, 1.3082e-04, 3.1528e-01],\n",
       "        [1.3797e-01, 6.2609e-03, 2.8766e-02, 2.4874e-02, 9.3293e-02, 5.7533e-03,\n",
       "         2.4198e-02, 5.4149e-03, 4.6816e-03, 4.3432e-03, 2.5157e-02, 7.5921e-02,\n",
       "         2.4141e-02, 1.1997e-01, 3.3222e-02, 3.0459e-03, 2.9895e-03, 4.7944e-02,\n",
       "         7.4285e-02, 3.0571e-02, 6.2045e-03, 1.5229e-02, 5.0764e-04, 5.0764e-03,\n",
       "         4.3996e-02, 1.5681e-02, 5.6405e-05, 1.4045e-01],\n",
       "        [5.0342e-01, 6.8306e-04, 1.7077e-03, 1.7077e-03, 1.5061e-01, 3.4153e-04,\n",
       "         3.4153e-04, 1.5710e-02, 4.0984e-02, 1.0246e-03, 1.0246e-03, 3.4153e-03,\n",
       "         2.0492e-03, 1.0246e-03, 1.6393e-01, 6.8306e-04, 3.4153e-04, 4.0984e-03,\n",
       "         2.7322e-03, 1.0246e-03, 6.9331e-02, 2.0492e-03, 2.3907e-03, 3.4153e-04,\n",
       "         3.7568e-03, 3.4153e-04, 3.4153e-04, 2.4590e-02],\n",
       "        [3.4175e-01, 5.9195e-04, 5.9195e-04, 5.9195e-04, 1.7680e-01, 3.9463e-04,\n",
       "         1.9732e-04, 6.0773e-02, 1.0063e-01, 5.9195e-04, 4.1436e-03, 2.7624e-02,\n",
       "         1.9732e-03, 5.3275e-03, 6.8074e-02, 1.9732e-04, 1.9732e-04, 2.1705e-02,\n",
       "         1.8942e-02, 3.5517e-03, 1.0063e-02, 5.9195e-04, 6.9061e-03, 1.9732e-04,\n",
       "         7.4980e-02, 5.9195e-04, 1.9732e-04, 7.1823e-02],\n",
       "        [1.8762e-01, 3.7895e-03, 1.8590e-03, 9.9385e-03, 2.0892e-01, 1.6445e-03,\n",
       "         5.0050e-04, 1.4300e-03, 1.7739e-01, 5.0050e-04, 1.7875e-03, 9.6239e-02,\n",
       "         4.3615e-03, 1.0725e-03, 4.9550e-02, 1.1440e-03, 2.8600e-04, 1.3585e-03,\n",
       "         6.7925e-03, 5.5770e-03, 2.3238e-02, 5.2195e-03, 1.2155e-03, 7.1500e-05,\n",
       "         1.1361e-01, 7.8650e-04, 7.1500e-05, 9.4023e-02],\n",
       "        [3.8846e-01, 1.6942e-02, 7.7961e-03, 3.7481e-03, 1.2279e-01, 2.9985e-04,\n",
       "         1.4993e-04, 8.9955e-04, 1.8846e-01, 1.1994e-03, 2.9985e-04, 8.9955e-04,\n",
       "         2.5337e-02, 3.1484e-03, 6.7916e-02, 5.8471e-03, 1.4993e-04, 1.4693e-02,\n",
       "         5.3973e-03, 7.4963e-04, 2.0990e-02, 5.9970e-04, 4.4978e-04, 1.4993e-04,\n",
       "         4.3178e-02, 1.7991e-03, 1.4993e-04, 7.7511e-02],\n",
       "        [1.6224e-01, 4.9033e-04, 1.1659e-02, 3.8409e-02, 7.4094e-02, 6.5377e-04,\n",
       "         1.4928e-02, 1.4710e-03, 9.4034e-02, 2.4516e-03, 3.2144e-03, 1.0678e-02,\n",
       "         1.0896e-03, 1.0390e-01, 2.7077e-02, 3.2689e-04, 1.6344e-04, 2.4516e-03,\n",
       "         1.5200e-02, 2.4190e-02, 5.2847e-03, 3.0509e-03, 6.5377e-04, 3.8137e-04,\n",
       "         2.5388e-02, 7.9542e-03, 5.4481e-05, 3.6851e-01],\n",
       "        [1.8839e-02, 1.7709e-02, 1.4444e-02, 2.3989e-02, 1.6704e-02, 4.3959e-03,\n",
       "         5.6518e-03, 2.1603e-02, 8.7918e-03, 2.1351e-03, 8.6662e-03, 7.7870e-02,\n",
       "         3.2906e-02, 3.0294e-01, 1.4569e-02, 1.2057e-02, 5.0239e-04, 1.3313e-01,\n",
       "         6.3426e-02, 1.4946e-02, 3.4665e-02, 2.2231e-02, 1.4444e-02, 5.7774e-03,\n",
       "         1.3062e-02, 6.9078e-03, 1.2560e-04, 1.0751e-01],\n",
       "        [1.9924e-01, 2.8463e-03, 1.8975e-03, 9.4877e-04, 1.8786e-01, 1.8975e-03,\n",
       "         9.4877e-04, 1.9450e-01, 5.8824e-02, 1.8975e-03, 1.8975e-03, 1.6129e-02,\n",
       "         1.8975e-03, 1.8975e-03, 5.6926e-02, 3.7951e-02, 9.4877e-04, 1.4421e-01,\n",
       "         1.6129e-02, 1.7078e-02, 4.7438e-03, 9.4877e-04, 9.4877e-04, 9.4877e-04,\n",
       "         1.2334e-02, 9.4877e-04, 9.4877e-04, 3.2258e-02],\n",
       "        [4.6667e-02, 3.3333e-03, 3.3333e-03, 3.3333e-03, 6.6667e-03, 3.3333e-03,\n",
       "         3.3333e-03, 3.3333e-03, 4.6667e-02, 3.3333e-03, 3.3333e-03, 6.6667e-03,\n",
       "         1.0000e-02, 3.3333e-03, 1.0000e-02, 3.3333e-03, 3.3333e-03, 6.6667e-03,\n",
       "         1.0000e-02, 3.3333e-03, 6.9000e-01, 3.3333e-03, 1.3333e-02, 3.3333e-03,\n",
       "         3.3333e-03, 3.3333e-03, 3.3333e-03, 9.6667e-02],\n",
       "        [1.8518e-01, 3.2998e-03, 7.8567e-03, 1.4771e-02, 1.3341e-01, 7.8567e-04,\n",
       "         6.0497e-03, 9.5852e-03, 2.3837e-01, 2.0427e-03, 7.1496e-03, 3.2527e-02,\n",
       "         1.2806e-02, 1.1078e-02, 6.8353e-02, 1.1785e-03, 1.3356e-03, 3.3470e-02,\n",
       "         1.5006e-02, 1.6420e-02, 1.9877e-02, 6.3639e-03, 1.7285e-03, 3.1427e-04,\n",
       "         6.0811e-02, 1.8856e-03, 7.8567e-05, 1.0827e-01],\n",
       "        [1.4777e-01, 2.7047e-03, 7.4994e-03, 1.2294e-03, 1.0880e-01, 3.6882e-04,\n",
       "         3.6882e-04, 1.5810e-01, 8.4214e-02, 3.6882e-04, 1.0204e-02, 3.4423e-02,\n",
       "         1.1188e-02, 3.0735e-03, 6.5404e-02, 6.3929e-03, 2.4588e-04, 6.8847e-03,\n",
       "         5.6799e-02, 9.4173e-02, 2.2867e-02, 1.8441e-03, 3.0735e-03, 1.2294e-04,\n",
       "         2.6555e-02, 1.3523e-03, 1.2294e-04, 1.4384e-01],\n",
       "        [1.8364e-01, 3.5727e-04, 3.2154e-03, 1.7864e-04, 1.2808e-01, 5.3591e-04,\n",
       "         5.3591e-04, 1.1576e-01, 9.5213e-02, 7.1454e-04, 1.7864e-04, 2.4116e-02,\n",
       "         8.9318e-04, 4.1086e-03, 1.1933e-01, 1.7864e-04, 1.7864e-04, 6.3058e-02,\n",
       "         6.4309e-03, 6.6988e-02, 1.4112e-02, 2.8582e-03, 2.1436e-03, 5.3591e-04,\n",
       "         6.1093e-02, 1.8935e-02, 1.7864e-04, 8.6459e-02],\n",
       "        [5.1850e-02, 3.2880e-02, 3.2880e-02, 4.3313e-02, 5.3746e-02, 6.3231e-03,\n",
       "         1.5175e-02, 1.8653e-02, 3.8571e-02, 4.7423e-03, 2.9719e-02, 9.5479e-02,\n",
       "         4.9004e-02, 8.7259e-02, 3.4777e-03, 5.3746e-03, 3.4777e-03, 1.3120e-01,\n",
       "         1.5017e-01, 2.6241e-02, 1.2646e-03, 1.2014e-02, 2.7506e-02, 1.1065e-02,\n",
       "         4.4262e-03, 1.4543e-02, 3.1616e-04, 4.9320e-02],\n",
       "        [2.4721e-01, 7.6894e-04, 3.8447e-04, 7.6894e-04, 2.1876e-01, 3.8447e-04,\n",
       "         3.8447e-04, 7.6894e-04, 3.5063e-01, 3.8447e-04, 1.5379e-03, 5.7670e-03,\n",
       "         3.8447e-04, 3.4602e-03, 5.9208e-02, 3.8447e-04, 3.8447e-04, 1.8839e-02,\n",
       "         3.8447e-04, 3.8447e-04, 3.0757e-03, 3.0757e-03, 3.8447e-04, 3.8447e-04,\n",
       "         4.6905e-02, 3.8447e-04, 3.8447e-04, 3.4218e-02],\n",
       "        [2.9363e-01, 2.0899e-03, 1.0449e-03, 9.4044e-03, 1.5674e-01, 3.1348e-03,\n",
       "         2.0899e-03, 2.5078e-02, 1.5569e-01, 1.0449e-03, 7.3145e-03, 1.4629e-02,\n",
       "         3.1348e-03, 6.1651e-02, 3.8662e-02, 1.0449e-03, 1.0449e-03, 2.4033e-02,\n",
       "         2.1944e-02, 9.4044e-03, 2.7168e-02, 1.0449e-03, 3.1348e-03, 1.0449e-03,\n",
       "         7.7325e-02, 2.0899e-03, 1.0449e-03, 5.4336e-02],\n",
       "        [1.4345e-01, 2.7586e-03, 6.8966e-03, 8.2759e-03, 5.1034e-02, 5.5172e-03,\n",
       "         1.3793e-03, 2.7586e-03, 1.4207e-01, 1.3793e-03, 1.3793e-03, 5.5172e-02,\n",
       "         2.7586e-03, 2.7586e-03, 5.7931e-02, 1.3793e-03, 1.3793e-03, 1.3793e-03,\n",
       "         4.4138e-02, 9.7931e-02, 8.2759e-03, 1.3793e-03, 5.5172e-03, 5.3793e-02,\n",
       "         4.2759e-02, 2.7586e-02, 1.3793e-03, 2.2759e-01],\n",
       "        [2.1869e-01, 2.8560e-03, 1.1832e-02, 2.7846e-02, 3.0804e-02, 1.3260e-03,\n",
       "         3.1620e-03, 2.3460e-03, 1.9686e-02, 2.4480e-03, 8.8739e-03, 1.1271e-01,\n",
       "         1.5198e-02, 1.8635e-01, 2.7744e-02, 1.6320e-03, 7.1399e-04, 2.9784e-02,\n",
       "         4.1004e-02, 1.0710e-02, 1.4484e-02, 1.0914e-02, 5.1000e-04, 2.9580e-03,\n",
       "         2.4480e-03, 8.0579e-03, 1.0200e-04, 2.0481e-01],\n",
       "        [3.5491e-01, 2.0610e-03, 1.2366e-03, 1.2366e-03, 1.5416e-01, 4.1220e-04,\n",
       "         8.2440e-04, 1.8137e-02, 1.5045e-01, 1.2366e-03, 1.2366e-03, 5.1113e-02,\n",
       "         1.4839e-02, 2.0610e-03, 4.5754e-02, 1.2366e-03, 4.1220e-04, 1.3603e-02,\n",
       "         2.0610e-03, 2.0610e-03, 3.0503e-02, 1.2366e-03, 1.6488e-03, 8.2440e-04,\n",
       "         6.1006e-02, 1.8961e-02, 4.1220e-04, 6.6364e-02],\n",
       "        [1.3758e-01, 4.0766e-02, 4.8127e-02, 5.2743e-02, 4.7784e-02, 1.3038e-02,\n",
       "         2.0898e-02, 2.7292e-02, 1.8465e-02, 7.5575e-02, 9.2449e-02, 4.9063e-02,\n",
       "         7.9193e-02, 3.5776e-02, 1.2320e-02, 1.6094e-02, 2.9007e-03, 5.1152e-02,\n",
       "         6.4128e-02, 4.0828e-02, 2.4641e-03, 1.1759e-02, 9.6067e-03, 4.2107e-03,\n",
       "         1.6718e-02, 2.9007e-02, 3.1191e-05, 3.1191e-05],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[27,:] = 0\n",
    "P[27,:]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all words err =  2.4606912554704077\n"
     ]
    }
   ],
   "source": [
    "all_words_err = []\n",
    "for word in words:\n",
    "  chs = ['<S>'] + list(word) + ['<E>']\n",
    "  per_word_err = [];\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    per_word_err.append(-torch.log(P[give_index(ch1),give_index(ch2)]))\n",
    "  all_words_err.append((sum(per_word_err)/len(per_word_err)).item())\n",
    " \n",
    "print('all words err = ',sum(all_words_err)/len(all_words_err))\n",
    "training_data_nll = all_words_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plt.hist(np.array(all_words_err), bins=20, density=True, alpha=0.7, color='g')  # use 20 bins, normalize the data to make the area under the histogram equal to 1, set transparency to 0.7, and color to green\n",
    "plt.xlabel('Values')  # add a label for the x-axis\n",
    "plt.ylabel('Frequency')  # add a label for the y-axis\n",
    "plt.title('Histogram of Random Data')  # add a title for the histogram\n",
    "plt.show()  # display the histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why product of probs?\n",
    "# <S> E M M A <E>\n",
    "# P(next_E/prev_<S>) = p1\n",
    "# P(next_M/prev_E) = p2\n",
    "# ..\n",
    "# P(next_<E>/prev_A) = p5\n",
    "# prob of this word being formed = P(next_E/prev<S>)*P(next_M/prev_E)...P(next_<E>/prev_A) [Independent events]\n",
    "\n",
    "# Another way?\n",
    "# Prob(next_E/prev_<S>) * prob(next_M/Prev_E_AND_prev_<S>)\n",
    "# basically don't forget independence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated names err =  2.4049953243508937\n"
     ]
    }
   ],
   "source": [
    "# err in bigram genrated names\n",
    "all_words_err = []\n",
    "# generate 10 names by bigram\n",
    "for n in range(3200):\n",
    "    name = ['<S>']\n",
    "    while True:\n",
    "        predicted_char = name[-1]\n",
    "        predicted_char_num = give_index(predicted_char)\n",
    "        p_first = N[predicted_char_num,:]/sum( N[predicted_char_num,:] )\n",
    "        ix = torch.multinomial(p_first, num_samples=1, replacement=True).item()\n",
    "        next_char = give_char(ix)\n",
    "        name.append(next_char)\n",
    "        if next_char == '<E>':\n",
    "            chs = list(name)\n",
    "            per_word_err = [];\n",
    "            for ch1,ch2 in zip(chs, chs[1:]):\n",
    "                per_word_err.append(-torch.log(P[give_index(ch1),give_index(ch2)]))\n",
    "            err = (sum(per_word_err)/len(per_word_err)).item()\n",
    "            all_words_err.append(err)\n",
    "            break\n",
    "#     print(''.join(name[1:-1]), ' err =',err)\n",
    "    \n",
    "        \n",
    "\n",
    "print('\\ngenerated names err = ', sum(all_words_err)/len(all_words_err))\n",
    "generated_data_nll = all_words_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 8.886116521081094\n",
      "p-value: 6.621404508006873e-19\n",
      "Rank-sum test statistic: 7.1999245433422026\n",
      "p-value: 6.024589018415706e-13\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Two independent sets of data\n",
    "data1 = training_data_nll\n",
    "data2 = generated_data_nll\n",
    "\n",
    "# Perform unpaired t-test\n",
    "t_stat, p_val = stats.ttest_ind(data1, data2)\n",
    "\n",
    "# Print results\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)\n",
    "\n",
    "# \n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate two sets of data\n",
    "group1 = training_data_nll\n",
    "group2 = generated_data_nll\n",
    "\n",
    "# Calculate the rank-sum test\n",
    "statistic, pvalue = stats.ranksums(group1, group2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Rank-sum test statistic:\", statistic)\n",
    "print(\"p-value:\", pvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of hard coding probs in matrix from data. we will train a neural network\n",
    "# simple neural network - 1 layer,\n",
    "# 27 neurons, softmax prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 4, 12, 12, 0] [4, 12, 12, 0, 27]\n"
     ]
    }
   ],
   "source": [
    "# training with only one example\n",
    "x_input = []\n",
    "y_output = []\n",
    "for word in words[:1]:\n",
    "    chs = ['<S>'] + list(word) + ['<E>']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]):\n",
    "        x_input.append(give_index(ch1))\n",
    "        y_output.append(give_index(ch2))\n",
    "print(x_input, y_output)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(torch.tensor(x_input), num_classes=28).float()\n",
    "print(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6212,  0.3371,  0.0368, -1.4117, -2.6682,  0.7502,  0.5853,  0.2949,\n",
      "          1.2908,  1.9005, -0.7969, -0.2400, -0.0407,  1.5936,  0.9982,  1.1730,\n",
      "          0.0440,  1.0036,  1.5495, -0.1538, -0.5094,  0.6079, -0.1501,  0.0976,\n",
      "          0.8421,  0.2928, -1.1467,  0.6068],\n",
      "        [ 1.1452, -0.9429,  2.5938,  1.0881,  0.4188,  0.8002,  0.8722, -0.5784,\n",
      "          0.1396,  1.3904, -1.2229,  0.1762,  0.7401, -0.6431, -1.1799, -1.5460,\n",
      "          0.2700,  0.2276, -2.2608, -0.0470, -0.4750,  0.9481, -0.2235, -0.8554,\n",
      "          1.5274, -0.3382,  2.9809, -1.4148],\n",
      "        [ 1.2231, -0.9603,  0.8788, -0.1341, -0.7883,  0.0519, -0.9387, -0.3936,\n",
      "         -0.4038,  0.6968, -0.8381,  0.3127, -0.9247, -2.1156, -0.3679, -1.0343,\n",
      "          0.0702, -0.4141,  0.2543, -1.4731, -0.2192, -1.1647, -0.4307,  1.1718,\n",
      "         -0.9127, -1.3996,  1.1432, -0.6446],\n",
      "        [ 1.2231, -0.9603,  0.8788, -0.1341, -0.7883,  0.0519, -0.9387, -0.3936,\n",
      "         -0.4038,  0.6968, -0.8381,  0.3127, -0.9247, -2.1156, -0.3679, -1.0343,\n",
      "          0.0702, -0.4141,  0.2543, -1.4731, -0.2192, -1.1647, -0.4307,  1.1718,\n",
      "         -0.9127, -1.3996,  1.1432, -0.6446],\n",
      "        [ 0.0918, -0.0154, -0.4408, -1.3075, -0.8535,  2.4998,  2.5184, -1.6352,\n",
      "          1.9334, -0.3786,  0.8597,  0.9718,  0.7621,  2.2149,  1.2813,  0.0141,\n",
      "         -0.4477,  0.1787,  1.1114,  0.3918,  0.4615,  0.9983, -1.2487, -0.6701,\n",
      "          0.1171,  1.3014, -0.3402,  0.5360]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((28,28), requires_grad=True)\n",
    "wx = xenc @ W\n",
    "print(wx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want probs, using softmax to convert Wx into probs\n",
    "exp_wx = wx.exp()\n",
    "prob = exp_wx/exp_wx.sum(1, keepdims=True)\n",
    "prob.shape # torch.Size([5, 28]) - for each 5 inputs, an 1 x 28 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.609539985656738\n",
      "3.504087209701538\n",
      "4.265148639678955\n",
      "2.1173064708709717\n",
      "3.786771059036255\n",
      "err total is  4.056570672988892\n"
     ]
    }
   ],
   "source": [
    "# loss calculated in elaborate way\n",
    "all_err = []\n",
    "for i in range(5):\n",
    "    p = prob[i,y_output[i]]\n",
    "    # err is difference of negative log likelihood between model(p) and dataset(p=1)\n",
    "    err  = -torch.log(p).item() - (-torch.log(torch.tensor(1))).item()\n",
    "    all_err.append(err)\n",
    "    print(err)\n",
    "\n",
    "print('err total is ',sum(all_err)/len(all_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss in one line \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting everything at one place - forward pass\n",
    "# initialize weights\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(3)\n",
    "W = torch.randn((28,28), requires_grad=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.192685127258301\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "wx = xenc @ W\n",
    "exp_wx = wx.exp()\n",
    "prob = exp_wx/exp_wx.sum(1, keepdims=True)\n",
    "loss = -prob[torch.arange(5),y_output].log().mean()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None\n",
    "loss.backward()\n",
    "W.data += -0.1*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss @ end of training =  2.464089870452881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a loop insted of manually forward and backward pass\n",
    "# --- input output dataset vecs\n",
    "x_input = []\n",
    "y_output = []\n",
    "for word in words:\n",
    "    chs = ['<S>'] + list(word) + ['<E>']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]):\n",
    "        x_input.append(give_index(ch1))\n",
    "        y_output.append(give_index(ch2))\n",
    "\n",
    "\n",
    "# one hot encoding of inputs\n",
    "xenc = F.one_hot(torch.tensor(x_input), num_classes=28).float()\n",
    "\n",
    "# initialize weights\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(3)\n",
    "# W = torch.randn((28,28), requires_grad=True, generator=generator)\n",
    "W = torch.randn((28,28), requires_grad=True)\n",
    "\n",
    "loss_over_time = []\n",
    "# forward pass and backward pass\n",
    "for p in range(200):\n",
    "    wx = xenc @ W\n",
    "    exp_wx = wx.exp()\n",
    "    prob = exp_wx/exp_wx.sum(1, keepdims=True)\n",
    "    loss = -prob[torch.arange(len(x_input)),y_output].log().mean()\n",
    "    loss_over_time.append(loss.item())\n",
    "    plt.plot(range(1,len(loss_over_time)+1), loss_over_time)\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -50*W.grad\n",
    "\n",
    "print('loss @ end of training = ', loss_over_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss by single layer is 2.4634, loss of bigram char model was around 2.4606. \n",
    "# both are essentially doing the same thing, taking the first character, predicting the second\n",
    "# the key difference is that in bigram model, we have explicitly mentioned the probability distributions from the data\n",
    "# while in the neural network model, it is via training that we had tuned the weights, which inturn spit out prob distributions\n",
    "\n",
    "# the bigram model is unscalable because if we had to use previous 2 chars, or prev 3 chars to predict the next char\n",
    "# the matrix of prob would increase and increase\n",
    "# but for neural network, we just have to change the architecture- num of layers and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting - 1\n",
    "# the W array in neural network approach and probability matrix are essentially same\n",
    "# explanation: when we one hot encode, we only take one row of weight matrix and predict.\n",
    "# this is similar to taking the row corresponding to first character in bigram prob matrix.\n",
    "# in bigram we define the matrix, in Neural network, we arrive at that matrix by training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([63.6494, 24.6710, 19.8554, 23.9320, 54.0614, 31.6699, 25.8377, 33.8341,\n",
      "        51.5107, 32.0481, 22.0913, 28.0229, 23.7220, 30.7426, 37.6717, 30.2539,\n",
      "        41.1396, 33.5537, 21.7882, 22.4419, 24.7084, 17.8164, 34.8693, 37.5048,\n",
      "        31.7034, 23.1123, 43.9781, 51.4458], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "diff_W_P = W - P\n",
    "print(sum(abs(diff_W_P)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting - 2\n",
    "# the N_counters + 1(call '1' as smoothening_term in bigram model), the + 1, which was done so that the -log(0) doesn't shoot to infinity is equialent to regularising\n",
    "# the loss function = -log(p) + reg_term*(W**2).sum()\n",
    "# the smoothening term prevents the loss function to go to infinity\n",
    "# similarly, in neural network training, it can happen weights go to zero, and spit output zero causing -log(p) to go to infinity\n",
    "# so, essentially: we add another extra term in loss function, so that weight doesn't drop to zero\n",
    "# [ ??? wouldn't adding a small number directly to weights be more better??. NO, because its essentially like changing structure of neural network, \n",
    "# or may be we have them the Biases, but biases can't be large enough to shift the results completely]\n",
    "\n",
    "# the parallel between smoothening_term in bigram and reg_term in neural network comes here:\n",
    "# the larger the numbers, more uniform will be the 28 x 28 matrix in both cases\n",
    "# in bigram if Ncounters + 10000 is done, all probs will be nearly same\n",
    "# in neural network, if part of loss function which optimizes W**2.sum() dominates, then model will try to generalize more\n",
    "# generalize more = not overfit, prefer the other part of loss func than minimizing the fit to existing dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
